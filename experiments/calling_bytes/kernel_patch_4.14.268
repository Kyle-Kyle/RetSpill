diff --git a/arch/x86/entry/common.c b/arch/x86/entry/common.c
index 38980034..623b985e 100644
--- a/arch/x86/entry/common.c
+++ b/arch/x86/entry/common.c
@@ -271,6 +271,7 @@ __visible inline void syscall_return_slowpath(struct pt_regs *regs)
 }
 
 #ifdef CONFIG_X86_64
+int arg_map[] = {3, 3, 3, 1, 2, 2, 2, 3, 3, 6, 3, 2, 1, 4, 4, 1, 3, 4, 4, 3, 3, 2, 1, 5, 0, 5, 3, 3, 3, 3, 3, 3, 1, 2, 0, 2, 2, 1, 3, 0, 4, 3, 3, 3, 6, 6, 3, 3, 2, 3, 2, 3, 3, 4, 5, 5, 5, 0, 0, 3, 1, 4, 2, 1, 3, 3, 4, 1, 2, 4, 5, 3, 3, 2, 1, 1, 2, 2, 3, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 3, 2, 2, 3, 3, 3, 1, 2, 2, 2, 1, 1, 4, 0, 3, 0, 1, 1, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 4, 3, 2, 2, 2, 3, 1, 1, 2, 2, 2, 3, 2, 3, 2, 2, 3, 1, 1, 1, 2, 2, 2, 1, 0, 0, 3, 2, 1, 5, 2, 1, 2, 1, 0, 1, 2, 5, 2, 2, 1, 4, 2, 2, 1, 3, 6, 3, 2, 6, 6, 4, 6, 6, 6, 6, 6, 6, 0, 3, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1, 6, 3, 3, 1, 2, 1, 5, 3, 3, 1, 3, 1, 6, 6, 5, 3, 1, 0, 4, 4, 3, 4, 2, 1, 1, 2, 2, 2, 4, 1, 4, 4, 3, 2, 6, 6, 3, 5, 4, 1, 5, 5, 2, 3, 4, 5, 5, 4, 5, 3, 2, 0, 3, 2, 4, 4, 3, 4, 5, 3, 4, 3, 4, 5, 3, 4, 3, 3, 6, 5, 1, 2, 3, 6, 4, 4, 4, 6, 4, 6, 3, 2, 1, 4, 4, 2, 4, 4, 2, 1, 3, 2, 1, 5, 5, 4, 5, 5, 2, 5, 4, 5, 3, 2, 1, 4, 2, 3, 6, 6, 5, 3, 3, 4, 5, 3, 3, 2, 5, 3, 5, 1, 2, 3, 6, 6, 6, 4, 2, 1, 5};
 __visible void do_syscall_64(struct pt_regs *regs)
 {
 	struct thread_info *ti = current_thread_info();
@@ -289,13 +290,100 @@ __visible void do_syscall_64(struct pt_regs *regs)
 	 */
 	if (likely((nr & __SYSCALL_MASK) < NR_syscalls)) {
 		nr = array_index_nospec(nr & __SYSCALL_MASK, NR_syscalls);
+		int arg_num = arg_map[nr];
+		switch(arg_num) {
+		case 0:
+		regs->ax = sys_call_table[nr](
+			0x4141414141414141, 0x4141414141414141, 0x4141414141414141,
+			0x4141414141414141, 0x4141414141414141, 0x4141414141414141);
+			break;
+		case 1:
+		regs->ax = sys_call_table[nr](
+			regs->di, 0x4141414141414141, 0x4141414141414141,
+			0x4141414141414141, 0x4141414141414141, 0x4141414141414141);
+			break;
+		case 2:
+		regs->ax = sys_call_table[nr](
+			regs->di, regs->si, 0x4141414141414141,
+			0x4141414141414141, 0x4141414141414141, 0x4141414141414141);
+			break;
+		case 3:
+		regs->ax = sys_call_table[nr](
+			regs->di, regs->si, regs->dx,
+			0x4141414141414141, 0x4141414141414141, 0x4141414141414141);
+			break;
+		case 4:
+		regs->ax = sys_call_table[nr](
+			regs->di, regs->si, regs->dx,
+			regs->r10, 0x4141414141414141, 0x4141414141414141);
+			break;
+		case 5:
+		regs->ax = sys_call_table[nr](
+			regs->di, regs->si, regs->dx,
+			regs->r10, regs->r8, 0x4141414141414141);
+			break;
+		case 6:
 		regs->ax = sys_call_table[nr](
 			regs->di, regs->si, regs->dx,
 			regs->r10, regs->r8, regs->r9);
+			break;
+		default:
+			printk("unexpected argument number: %d, for syscall %d!\n", arg_num, nr);
+			panic("panicpanicpanic");
+		}
+
+		// regs->ax = sys_call_table[nr](
+		// 	regs->di, regs->si, regs->dx,
+		// 	regs->r10, regs->r8, regs->r9);
 	}
 
 	syscall_return_slowpath(regs);
 }
+
+DEFINE_PER_CPU(long, syscall_cnt) = 0;
+DEFINE_PER_CPU(long, gadget_cnt) = 0;
+DEFINE_PER_CPU(long, max_gadget) = 0;
+__visible void inspect_stack_64(long rsp)
+{
+
+	long *ptr;
+	long *arr;
+	long var1, var2, var3;
+	int i, cnt = 0;
+
+	// increase syscall counter
+	ptr = &get_cpu_var(syscall_cnt);
+	*ptr += 1;
+	var1 = *ptr;
+	put_cpu_var(syscall_cnt);
+
+	// increase taint counter
+	ptr = &get_cpu_var(gadget_cnt);
+	arr = (long *)(rsp-0x200);
+	for(i=0; i<0x200/8; i++) {
+		if(arr[i] == 0x4141414141414141) cnt += 1;
+	}
+	*ptr += cnt;
+	var2 = *ptr;
+	put_cpu_var(gadget_cnt);
+
+	// record max
+	ptr = &get_cpu_var(max_gadget);
+	if(cnt > *ptr) *ptr = cnt;
+	var3 = *ptr;
+	put_cpu_var(max_gadget);
+
+	if(var1 % 0x10000 == 0) {
+		int cpu_id = get_cpu();
+		printk("cpu_id: %d, max_gadget: %d, syscall_cnt: 0x%lx, gadget_cnt: 0x%lx\n", cpu_id, var3, var1, var2);
+		put_cpu();
+	}
+}
+
+__visible void clear_stack_64(long rsp)
+{
+	memset((void *)(rsp-0x200), 0, 0x200-8);
+}
 #endif
 
 #if defined(CONFIG_X86_32) || defined(CONFIG_IA32_EMULATION)
diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S
index ac389ffb..0b4f3247 100644
--- a/arch/x86/entry/entry_64.S
+++ b/arch/x86/entry/entry_64.S
@@ -232,6 +232,13 @@ GLOBAL(entry_SYSCALL_64_after_hwframe)
 	movq	%rsp, %rdi
 	call	do_syscall_64		/* returns with IRQs disabled */
 
+	pushq	%rax
+	movq	%rsp, %rdi
+	call	inspect_stack_64	/* check taint on stack after each syscall execution */
+	movq	%rsp, %rdi
+	call	clear_stack_64		/* clear stack after the syscall execution */
+	popq    %rax
+
 	TRACE_IRQS_IRETQ		/* we're about to change IF */
 
 	/*
